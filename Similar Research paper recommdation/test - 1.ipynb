{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-21T11:05:21.485052Z",
     "start_time": "2024-09-21T11:05:16.280528Z"
    }
   },
   "source": "!pip install -U sentence-transformers",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\bhara\\anaconda3\\lib\\site-packages (3.1.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.38.0 in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.44.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\bhara\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.4.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\bhara\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\bhara\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (1.13.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.25.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\bhara\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (10.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\bhara\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (3.12.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\bhara\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (2023.9.2)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\bhara\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\bhara\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\bhara\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\bhara\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\bhara\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\bhara\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\bhara\\appdata\\roaming\\python\\python311\\site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (1.26.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\bhara\\appdata\\roaming\\python\\python311\\site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (2023.8.8)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\bhara\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\bhara\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn->sentence-transformers) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\bhara\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\bhara\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bhara\\appdata\\roaming\\python\\python311\\site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bhara\\appdata\\roaming\\python\\python311\\site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\bhara\\appdata\\roaming\\python\\python311\\site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bhara\\appdata\\roaming\\python\\python311\\site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\bhara\\appdata\\roaming\\python\\python311\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T11:08:08.846186Z",
     "start_time": "2024-09-21T11:08:08.841967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sentence_transformers import SentenceTransformer,util\n",
    "import requests\n",
    "import os\n",
    "import json"
   ],
   "id": "e8b7b8107a0bee91",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T11:09:19.012037Z",
     "start_time": "2024-09-21T11:09:13.796508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = requests.get('https://sbert.net/datasets/emnlp2016-2018.json')\n",
    "papers = json.loads(response.text)"
   ],
   "id": "b85a61ed57e3db8c",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T11:27:03.706505Z",
     "start_time": "2024-09-21T11:27:03.700081Z"
    }
   },
   "cell_type": "code",
   "source": "papers[597]",
   "id": "4204066716c41601",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Streaming word similarity mining on the cheap',\n",
       " 'abstract': 'We consider the problem of learning distributed representations for documents in data streams. The documents are represented as low-dimensional vectors and are jointly learned with distributed vector representations of word tokens using a hierarchical framework with two embedded neural language models. In particular, we exploit the context of documents in streams and use one of the language models to model the document sequences, and the other to model word sequences within them. The models learn continuous vector representations for both word tokens and documents such that semantically similar documents and words are close in a common vector space. We discuss extensions to our model, which can be applied to personalized recommendation and social relationship mining by adding further user layers to the hierarchy, thus learning user-specific vectors to represent individual preferences. We validated the learned representations on a public movie rating data set from MovieLens, as well as on a large-scale Yahoo News data comprising three months of user activity logs collected on Yahoo servers. The results indicate that the proposed model can learn useful representations of both documents and word tokens, outperforming the current state-of-the-art by a large margin.',\n",
       " 'url': 'http://aclweb.org/anthology/D18-1172',\n",
       " 'venue': 'EMNLP',\n",
       " 'year': '2018'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T11:13:05.464197Z",
     "start_time": "2024-09-21T11:10:49.917718Z"
    }
   },
   "cell_type": "code",
   "source": "model = SentenceTransformer('allenai-specter')",
   "id": "d8078266cceab82e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "95b9a78cd07e49378221ce464294f028"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhara\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\bhara\\.cache\\huggingface\\hub\\models--sentence-transformers--allenai-specter. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "549e33b2613347a38fcd92b11faf0fae"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "README.md:   0%|          | 0.00/2.77k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "924c13d32a9c42318c7d514a8a01da8d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a6c19ad3332f4d8a90deabfa0e6d090c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/622 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "63badacd815345d7a11bc3346670ad8e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d150f6e1f13943eebf199d1daa637ab3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/331 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8cfac6121bd3490080ef1cc7803d2722"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/222k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "316c926700e3498da7faccc40644e37a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/462k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "053697de827e4df5852a56b490ebca75"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f9ba1a7462ba49ba9de96d3acb831e8c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhara\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a8e6efc7952e4e89b610f94772f7f896"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T11:18:27.579849Z",
     "start_time": "2024-09-21T11:18:27.573508Z"
    }
   },
   "cell_type": "code",
   "source": "paper_texts = [paper['title'] + '[SEP]' + paper['abstract'] for paper in papers]",
   "id": "8c9cf67d1114bd8e",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T11:21:19.927146Z",
     "start_time": "2024-09-21T11:18:28.629865Z"
    }
   },
   "cell_type": "code",
   "source": "corpus_embeddings = model.encode(paper_texts, convert_to_tensor=True,show_progress_bar=True)",
   "id": "cd6af85d0f8e4cef",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/31 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "84d010b9782546bbbb982a54866550e9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T11:27:42.546063Z",
     "start_time": "2024-09-21T11:27:42.538180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def Search(title,abstract):\n",
    "    query_embedding = model.encode(title + '[SEP]' + abstract,convert_to_tensor=True)\n",
    "    \n",
    "    search_hits = util.semantic_search(query_embedding,corpus_embeddings,top_k=5)[0]\n",
    "    \n",
    "    print(\"\\n\\nMost Similar Papers:\\n\\n\")\n",
    "    \n",
    "    for hit in search_hits:\n",
    "        related_paper = papers[hit['corpus_id']]\n",
    "        print(related_paper['title']+'\\n') \n",
    "        print(related_paper['abstract']+'\\n')\n",
    "        print(related_paper['year'])\n",
    "        print('\\n\\n\\n')\n",
    "    \n",
    "    "
   ],
   "id": "4802ff610c3d86dd",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T11:27:43.581811Z",
     "start_time": "2024-09-21T11:27:43.527462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "title = 'a novel method to find similar documents'\n",
    "abstract = 'a novel method to find similar documents'\n",
    "Search(title,abstract)"
   ],
   "id": "6e8c9b1e1a355bde",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Most Similar Papers:\n",
      "\n",
      "\n",
      "Quantifying the Effects of Text Duplication on Semantic Models\n",
      "\n",
      "One of the important factors that make a search engine fast and accurate is a concise and duplicate free index. In order to remove duplicate and near-duplicate documents from the index, a search engine needs a swift and reliable duplicate and near-duplicate text document detection system. Traditional approaches to this problem, such as brute force comparisons or simple hash-based algorithms are not suitable as they are not scalable and are not capable of detecting near-duplicate documents effectively. In this paper, a new signature-based approach to text similarity detection is introduced which is fast, scalable, reliable and needs less storage space. The proposed method is examined on popular text document data-sets such as CiteseerX, Enron, Gold Set of Near-duplicate News Articles and etc. The results are promising and comparable with the best cutting-edge algorithms, considering the accuracy and performance. The proposed method is based on the idea of using reference texts to generate signatures for text documents. The novelty of this paper is the use of genetic algorithms to generate better reference texts.\n",
      "\n",
      "2017\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Affinity-Preserving Random Walk for Multi-Document Summarization\n",
      "\n",
      "The increasing amount of online content motivated the development of multi-document summarization methods. In this work, we explore straightforward approaches to extend single-document summarization methods to multi-document summarization. The proposed methods are based on the hierarchical combination of single-document summaries, and achieves state of the art results.\n",
      "\n",
      "2017\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Streaming word similarity mining on the cheap\n",
      "\n",
      "We consider the problem of learning distributed representations for documents in data streams. The documents are represented as low-dimensional vectors and are jointly learned with distributed vector representations of word tokens using a hierarchical framework with two embedded neural language models. In particular, we exploit the context of documents in streams and use one of the language models to model the document sequences, and the other to model word sequences within them. The models learn continuous vector representations for both word tokens and documents such that semantically similar documents and words are close in a common vector space. We discuss extensions to our model, which can be applied to personalized recommendation and social relationship mining by adding further user layers to the hierarchy, thus learning user-specific vectors to represent individual preferences. We validated the learned representations on a public movie rating data set from MovieLens, as well as on a large-scale Yahoo News data comprising three months of user activity logs collected on Yahoo servers. The results indicate that the proposed model can learn useful representations of both documents and word tokens, outperforming the current state-of-the-art by a large margin.\n",
      "\n",
      "2018\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Uncertainty-aware generative models for inferring document class prevalence\n",
      "\n",
      "Importance of document clustering is now widely acknowledged by researchers for better management, smart navigation, efficient filtering, and concise summarization of large collection of documents like World Wide Web (WWW). The next challenge lies in semantically performing clustering based on the semantic contents of the document. The problem of document clustering has two main components: (1) to represent the document in such a form that inherently captures semantics of the text. This may also help to reduce dimensionality of the document, and (2) to define a similarity measure based on the semantic representation such that it assigns higher numerical values to document pairs which have higher semantic relationship. Feature space of the documents can be very challenging for document clustering. A document may contain multiple topics, it may contain a large set of class-independent general-words, and a handful class-specific core-words. With these features in mind, traditional agglomerative clustering algorithms, which are based on either Document Vector model (DVM) or Suffix Tree model (STC), are less efficient in producing results with high cluster quality. This paper introduces a new approach for document clustering based on the Topic Map representation of the documents. The document is being transformed into a compact form. A similarity measure is proposed based upon the inferred information through topic maps data and structures. The suggested method is implemented using agglomerative hierarchal clustering and tested on standard Information retrieval (IR) datasets. The comparative experiment reveals that the proposed approach is effective in improving the cluster quality.\n",
      "\n",
      "2018\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Identifying Semantically Deviating Outlier Documents\n",
      "\n",
      "Outlier detection aims to identify unusual data instances that deviate from expected patterns. The outlier detection is particularly challenging when outliers are context dependent and when they are defined by unusual combinations of multiple outcome variable values. In this paper, we develop and study a new conditional outlier detection approach for multivariate outcome spaces that works by (1) transforming the conditional detection to the outlier detection problem in a new (unconditional) space and (2) defining outlier scores by analyzing the data in the new space. Our approach relies on the classifier chain decomposition of the multi-dimensional classification problem that lets us transform the output space into a probability vector, one probability for each dimension of the output space. Outlier scores applied to these transformed vectors are then used to detect the outliers. Experiments on multiple multi-dimensional classification problems with the different outlier injection rates show that our methodology is robust and able to successfully identify outliers when outliers are either sparse (manifested in one or very few dimensions) or dense (affecting multiple dimensions).\n",
      "\n",
      "2017\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6d6db4a0af42c5e4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
